{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd98217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from torch.nn.functional import softmax\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c08c1e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================ratings==========================\n",
      "   user id  item id  rating  timestamp\n",
      "0      196      242       3  881250949\n",
      "1      186      302       3  891717742\n",
      "2       22      377       1  878887116\n",
      "3      244       51       2  880606923\n",
      "4      166      346       1  886397596\n",
      "=====================movies==========================\n",
      "   movie id        movie title release date  video release date  \\\n",
      "0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
      "1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
      "2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
      "3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
      "4         5     Copycat (1995)  01-Jan-1995                 NaN   \n",
      "\n",
      "                                            IMDb URL  unknown  Action  \\\n",
      "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...        0       0   \n",
      "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...        0       1   \n",
      "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...        0       0   \n",
      "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...        0       1   \n",
      "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)        0       0   \n",
      "\n",
      "   Adventure  Animation  Children's  ...  Fantasy  Film-Noir  Horror  Musical  \\\n",
      "0          0          1           1  ...        0          0       0        0   \n",
      "1          1          0           0  ...        0          0       0        0   \n",
      "2          0          0           0  ...        0          0       0        0   \n",
      "3          0          0           0  ...        0          0       0        0   \n",
      "4          0          0           0  ...        0          0       0        0   \n",
      "\n",
      "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
      "0        0        0       0         0    0        0  \n",
      "1        0        0       0         1    0        0  \n",
      "2        0        0       0         1    0        0  \n",
      "3        0        0       0         0    0        0  \n",
      "4        0        0       0         1    0        0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "=====================users==========================\n",
      "   user id  age gender  occupation zip code\n",
      "0        1   24      M  technician    85711\n",
      "1        2   53      F       other    94043\n",
      "2        3   23      M      writer    32067\n",
      "3        4   24      M  technician    43537\n",
      "4        5   33      F       other    15213\n"
     ]
    }
   ],
   "source": [
    "# u.data：user id | item id | rating | timestamp\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user id','item id','rating','timestamp'], encoding = \"UTF-8\")\n",
    "\n",
    "'''u.item     -- Information about the items (movies); this is a tab separated\n",
    "              list of\n",
    "              movie id | movie title | release date | video release date |\n",
    "              IMDb URL | unknown | Action | Adventure | Animation |\n",
    "              Children's | Comedy | Crime | Documentary | Drama | Fantasy |\n",
    "              Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |\n",
    "              Thriller | War | Western |\n",
    "              The last 19 fields are the genres, a 1 indicates the movie\n",
    "              is of that genre, a 0 indicates it is not; movies can be in\n",
    "              several genres at once.\n",
    "              The movie ids are the ones used in the u.data data set.\n",
    "'''\n",
    "movies = pd.read_csv('ml-100k/u.item', sep='|', names=[\"movie id\",\"movie title\",\"release date\",\"video release date\",\"IMDb URL\",\n",
    "                                                        \"unknown\",\"Action\",\"Adventure\",\"Animation\",\"Children's\",\"Comedy\",\"Crime\",\n",
    "                                                        \" Documentary\",\"Drama\",\"Fantasy\",\"Film-Noir\",\"Horror\",\"Musical\",\"Mystery\",\n",
    "                                                        \"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\" ], encoding = \"ISO-8859-1\")\n",
    "'''u.user     -- Demographic information about the users; this is a tab\n",
    "              separated list of\n",
    "              user id | age | gender | occupation | zip code\n",
    "              The user ids are the ones used in the u.data data set.\n",
    "'''\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=['user id','age','gender','occupation','zip code'], encoding = \"ISO-8859-1\")\n",
    "print(\"=====================ratings==========================\")\n",
    "print(ratings.head())\n",
    "print(\"=====================movies==========================\")\n",
    "print(movies.head())\n",
    "print(\"=====================users==========================\")\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f97fa8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user id  age  gender  occupation\n",
      "0        1   24       1           1\n",
      "1        2   53       0           2\n",
      "2        3   23       1           3\n",
      "3        4   24       1           1\n",
      "4        5   33       0           2\n"
     ]
    }
   ],
   "source": [
    "Users = users.drop(\"zip code\",axis = 1)\n",
    "# 将性别列转换为 0/1 变量\n",
    "Users['gender'] = Users['gender'].map({'M': 1, 'F': 0})\n",
    "# 将职业列按顺序进行数字编码\n",
    "occupations = Users['occupation'].unique()\n",
    "occupation_mapping = {occ: i+1 for i, occ in enumerate(occupations)}\n",
    "Users['occupation'] = Users['occupation'].map(occupation_mapping)\n",
    "\n",
    "# 将Users写入CSV文件\n",
    "Users.to_csv('Users.csv', index=True)\n",
    "print(Users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe8eb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user id  movie id  rating\n",
      "0      196       242       3\n",
      "1      186       302       3\n",
      "2       22       377       1\n",
      "3      244        51       2\n",
      "4      166       346       1\n"
     ]
    }
   ],
   "source": [
    "Ratings = ratings.drop(\"timestamp\",axis = 1)\n",
    "Ratings = Ratings.rename(columns={'item id': 'movie id'})\n",
    "print(Ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59bfe29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie id  Action  Adventure  Animation  Children's  Comedy  Crime  \\\n",
      "0         1       0          0          1           1       1      0   \n",
      "1         2       1          1          0           0       0      0   \n",
      "2         3       0          0          0           0       0      0   \n",
      "3         4       1          0          0           0       1      0   \n",
      "4         5       0          0          0           0       0      1   \n",
      "\n",
      "    Documentary  Drama  Fantasy  Film-Noir  Horror  Musical  Mystery  Romance  \\\n",
      "0             0      0        0          0       0        0        0        0   \n",
      "1             0      0        0          0       0        0        0        0   \n",
      "2             0      0        0          0       0        0        0        0   \n",
      "3             0      1        0          0       0        0        0        0   \n",
      "4             0      1        0          0       0        0        0        0   \n",
      "\n",
      "   Sci-Fi  Thriller  War  Western  \n",
      "0       0         0    0        0  \n",
      "1       0         1    0        0  \n",
      "2       0         1    0        0  \n",
      "3       0         0    0        0  \n",
      "4       0         1    0        0  \n"
     ]
    }
   ],
   "source": [
    "# 移除unknown是因为unknown可以用其他类别特征都为0表示\n",
    "Movies = movies.drop([\"video release date\",\"IMDb URL\",\"release date\",\"movie title\",\"unknown\"],axis = 1)\n",
    "Movies.to_csv('Movies.csv', index=True)\n",
    "print(Movies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00073585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user id  movie id  rating  age  gender  occupation  Action  Adventure  \\\n",
      "0      196       242       3   49       1           3       0          0   \n",
      "1      186       302       3   39       0           4       0          0   \n",
      "2       22       377       1   25       1           3       0          0   \n",
      "3      244        51       2   28       1           1       0          0   \n",
      "4      166       346       1   47       1           8       0          0   \n",
      "\n",
      "   Animation  Children's  ...  Fantasy  Film-Noir  Horror  Musical  Mystery  \\\n",
      "0          0           0  ...        0          0       0        0        0   \n",
      "1          0           0  ...        0          1       0        0        1   \n",
      "2          0           1  ...        0          0       0        0        0   \n",
      "3          0           0  ...        0          0       0        0        0   \n",
      "4          0           0  ...        0          0       0        0        0   \n",
      "\n",
      "   Romance  Sci-Fi  Thriller  War  Western  \n",
      "0        0       0         0    0        0  \n",
      "1        0       0         1    0        0  \n",
      "2        0       0         0    0        0  \n",
      "3        1       0         0    1        1  \n",
      "4        0       0         0    0        0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.merge(Ratings, Users, on='user id')\n",
    "data = pd.merge(merged_data, Movies, on='movie id')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dca439f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max UserID: 943\n",
      "Max MovieID: 1682\n",
      "torch.int32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 找出UserID列和MovieID列的最大值并打印\n",
    "max_user_id = data['user id'].max()\n",
    "max_movie_id = data['movie id'].max()\n",
    "print(f'Max UserID: {max_user_id}')\n",
    "print(f'Max MovieID: {max_movie_id}')\n",
    "# 将数据分为特征和标签\n",
    "y = data['rating']\n",
    "X = data.drop('rating',axis = 1)\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_tensor = torch.tensor(X_train.values).int()\n",
    "X_test_tensor = torch.tensor(X_test.values).int()\n",
    "y_train_tensor = torch.tensor(y_train.values).float()\n",
    "y_test_tensor = torch.tensor(y_test.values).float()\n",
    "print(X_train_tensor.dtype)\n",
    "print(y_test_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99e8cf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user id', 'movie id', 'age', 'gender', 'occupation', 'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime', ' Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
      "torch.Size([80000, 23])\n"
     ]
    }
   ],
   "source": [
    "header = list(X.columns)\n",
    "print(header)\n",
    "print(X_train_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1884c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features (Tensor): 特征数据张量。\n",
    "            labels (Tensor): 标签数据张量。\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集中的数据点总数\"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"根据给定的索引 idx 返回特征和标签\"\"\"\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6c8abd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001B2FE1B13C0>\n"
     ]
    }
   ],
   "source": [
    "# 创建训练集和测试集的 Dataset\n",
    "train_dataset = RatingsDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = RatingsDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# 创建DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c60228b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RatingPredictor(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, user_embedding_dim, movie_embedding_dim, user_feature_dim, movie_feature_dim, nhead,num_encoder_layers,dim_feedforward, dropout_rate):\n",
    "        super(RatingPredictor, self).__init__()\n",
    "\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users + 1, embedding_dim=user_embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(num_embeddings=num_movies + 1, embedding_dim=movie_embedding_dim)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=user_embedding_dim + movie_embedding_dim + user_feature_dim + movie_feature_dim,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers= num_encoder_layers)\n",
    "\n",
    "        self.fc = nn.Linear(user_embedding_dim + movie_embedding_dim + user_feature_dim + movie_feature_dim, 1)\n",
    "\n",
    "    def forward(self, user_ids, movie_ids, user_features, movie_features):\n",
    "        user_embed = self.user_embedding(user_ids)\n",
    "        movie_embed = self.movie_embedding(movie_ids)\n",
    "        \n",
    "        # 用户ID的Embedding与用户特征拼接\n",
    "        user_combined_features = torch.cat([user_embed, user_features], dim=-1)\n",
    "        # 电影ID的Embedding与电影特征拼接\n",
    "        movie_combined_features = torch.cat([movie_embed, movie_features], dim=-1)\n",
    "        \n",
    "        # 将用户和电影的组合特征拼接\n",
    "        combined_features = torch.cat([user_combined_features, movie_combined_features], dim=-1).unsqueeze(1)  # 增加一个维度以符合Transformer输入要求\n",
    "        \n",
    "        # 通过Transformer Encoder\n",
    "        transformer_output = self.transformer_encoder(combined_features)\n",
    "        transformer_output = transformer_output.squeeze(1)  # 移除多余的维度\n",
    "        \n",
    "        # 通过全连接层\n",
    "        output = self.fc(transformer_output)\n",
    "\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2353869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fca7eb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RatingPredictor(\n",
      "  (user_embedding): Embedding(944, 32)\n",
      "  (movie_embedding): Embedding(1863, 32)\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=85, out_features=85, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=85, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=85, bias=True)\n",
      "        (norm1): LayerNorm((85,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((85,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=85, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pang_\\.conda\\envs\\py10\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# 模型超参数\n",
    "# num_users, num_movies, user_embedding_dim=32, \n",
    "# movie_embedding_dim=32, user_feature_dim=3, movie_feature_dim=18, nhead=4, dim_feedforward=2048, dropout_rate=0.1\n",
    "num_users = 943\n",
    "num_movies = 1862\n",
    "num_encoder_layers = 1\n",
    "user_embedding_dim=32\n",
    "movie_embedding_dim=32\n",
    "user_feature_dim=3\n",
    "movie_feature_dim=18\n",
    "# dmodel = 85\n",
    "nhead=5\n",
    "dim_feedforward=1024#太大就会用太多计算资源\n",
    "dropout_rate=0.1# 根据你的数据集进行调整\n",
    "\n",
    "model = RatingPredictor(\n",
    "    num_users=num_users,\n",
    "    num_movies=num_movies,\n",
    "    user_embedding_dim=user_embedding_dim,\n",
    "    movie_embedding_dim=movie_embedding_dim,\n",
    "    user_feature_dim=user_feature_dim,\n",
    "    movie_feature_dim=movie_feature_dim,\n",
    "    nhead=nhead,\n",
    "    num_encoder_layers=num_encoder_layers,\n",
    "    dim_feedforward=dim_feedforward,\n",
    "    dropout_rate=dropout_rate\n",
    ")\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72144987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评估\n",
    "def model_eval(model,test_loader):\n",
    "    model.eval()  # 将模型置于评估模式\n",
    "\n",
    "    # 在评估之前定义一些变量以记录评估结果\n",
    "    running_mse = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for features, labels in test_loader:\n",
    "            user_ids = features[:, 0].long().to(device)  # 用户ID\n",
    "            movie_ids = features[:, 1].long().to(device)  # 电影ID\n",
    "            user_feats = features[:, 2:5].to(device)  # 用户特征\n",
    "            movie_feats = features[:, 5:].to(device)  # 电影特征\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            predictions = model(user_ids, movie_ids, user_feats, movie_feats)\n",
    "            prediction_clipped = predictions.clamp(min=1, max=5)\n",
    "            \n",
    "            # 计算均方误差\n",
    "            loss = criterion(prediction_clipped, labels)\n",
    "            running_mse += loss.item() * features.size(0)\n",
    "            total_samples += features.size(0)\n",
    "\n",
    "    # 计算平均均方误差\n",
    "    mse = running_mse / total_samples\n",
    "#     rmse = torch.sqrt(mse)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "820ad787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([418, 815, 897, 606, 118, 640, 116, 642], device='cuda:0') tensor([269, 380,  95, 637, 551, 663, 661, 102], device='cuda:0') tensor([[55,  0, 17],\n",
      "        [32,  1,  2],\n",
      "        [30,  1,  2],\n",
      "        [28,  1, 11],\n",
      "        [21,  1,  5],\n",
      "        [20,  1,  6],\n",
      "        [40,  1, 18],\n",
      "        [18,  0,  6]], device='cuda:0', dtype=torch.int32) tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       device='cuda:0', dtype=torch.int32)\n",
      "torch.Size([8]) torch.Size([8]) torch.Size([8, 3]) torch.Size([8, 18])\n"
     ]
    }
   ],
   "source": [
    "# epoch = 300 其实是301轮\n",
    "PATH = './checkpoint/rating_regressor_300.pth'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        features, labels = data\n",
    "        user_ids = features[:, 0].long().to(device)  # 用户ID\n",
    "        movie_ids = features[:, 1].long().to(device)  # 电影ID\n",
    "        user_feats = features[:, 2:5].to(device)  # 用户特征\n",
    "        movie_feats = features[:, 5:].to(device)  # 电影特征\n",
    "        print(user_ids,movie_ids,user_feats,movie_feats)\n",
    "        print(user_ids.size(),movie_ids.size(),user_feats.size(),movie_feats.size())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c92a74a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pang_\\.conda\\envs\\py10\\lib\\site-packages\\torch\\nn\\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 1.2035,MSE:1.1314000712901353\n",
      "Epoch 2, Average Loss: 1.0415,MSE:0.9893959114834666\n",
      "Epoch 3, Average Loss: 0.9789,MSE:0.9135288128580898\n",
      "Epoch 4, Average Loss: 0.9560,MSE:0.9480244465880096\n",
      "Epoch 5, Average Loss: 0.9345,MSE:0.9040041882034391\n",
      "Epoch 6, Average Loss: 0.9202,MSE:0.9248678304813802\n",
      "Epoch 7, Average Loss: 0.9001,MSE:0.8657799772314727\n",
      "Epoch 8, Average Loss: 0.8904,MSE:0.8704155466578901\n",
      "Epoch 9, Average Loss: 0.8767,MSE:0.8364718932341785\n",
      "Epoch 10, Average Loss: 0.8674,MSE:0.8426222413949669\n",
      "Epoch 11, Average Loss: 0.8573,MSE:0.8694272248327732\n",
      "Epoch 12, Average Loss: 0.8535,MSE:0.8402617111448198\n",
      "Epoch 13, Average Loss: 0.8480,MSE:0.8119284650109708\n",
      "Epoch 14, Average Loss: 0.8415,MSE:0.8600026292067021\n",
      "Epoch 15, Average Loss: 0.8389,MSE:0.8142544409230351\n",
      "Epoch 16, Average Loss: 0.8375,MSE:0.8075948779158294\n",
      "Epoch 17, Average Loss: 0.8329,MSE:0.8250312206327916\n",
      "Epoch 18, Average Loss: 0.8274,MSE:0.8033192804407329\n",
      "Epoch 19, Average Loss: 0.8240,MSE:0.8301366760080681\n",
      "Epoch 20, Average Loss: 0.8219,MSE:0.8119040590371936\n",
      "Epoch 21, Average Loss: 0.8202,MSE:0.7827515818532557\n",
      "Epoch 22, Average Loss: 0.8144,MSE:0.789468156767264\n",
      "Epoch 23, Average Loss: 0.8122,MSE:0.7786395530339331\n",
      "Epoch 24, Average Loss: 0.8095,MSE:0.7753198533548042\n",
      "Epoch 25, Average Loss: 0.8067,MSE:0.7863074863614514\n",
      "Epoch 26, Average Loss: 0.8009,MSE:0.7637563189782203\n",
      "Epoch 27, Average Loss: 0.7999,MSE:0.7673834804572165\n",
      "Epoch 28, Average Loss: 0.7967,MSE:0.7678374211218209\n",
      "Epoch 29, Average Loss: 0.7940,MSE:0.7696959763046354\n",
      "Epoch 30, Average Loss: 0.7871,MSE:0.7710029992304742\n",
      "Epoch 31, Average Loss: 0.7844,MSE:0.7579973260758445\n",
      "Epoch 32, Average Loss: 0.7816,MSE:0.7489544375460595\n",
      "Epoch 33, Average Loss: 0.7743,MSE:0.7374630538225174\n",
      "Epoch 34, Average Loss: 0.7716,MSE:0.7374102786857635\n",
      "Epoch 35, Average Loss: 0.7723,MSE:0.7475707625102251\n",
      "Epoch 36, Average Loss: 0.7700,MSE:0.7485739359633997\n",
      "Epoch 37, Average Loss: 0.7643,MSE:0.727391458395496\n",
      "Epoch 38, Average Loss: 0.7616,MSE:0.7230869594767689\n",
      "Epoch 39, Average Loss: 0.7603,MSE:0.7210107688471675\n",
      "Epoch 40, Average Loss: 0.7573,MSE:0.7250137717336417\n",
      "Epoch 41, Average Loss: 0.7548,MSE:0.7119329386491329\n",
      "Epoch 42, Average Loss: 0.7516,MSE:0.7109848469603807\n",
      "Epoch 43, Average Loss: 0.7496,MSE:0.7255169413072988\n",
      "Epoch 44, Average Loss: 0.7470,MSE:0.7047073085254059\n",
      "Epoch 45, Average Loss: 0.7457,MSE:0.6981879500541835\n",
      "Epoch 46, Average Loss: 0.7450,MSE:0.6977664839394391\n",
      "Epoch 47, Average Loss: 0.7413,MSE:0.6963163664158434\n",
      "Epoch 48, Average Loss: 0.7404,MSE:0.7150468526205048\n",
      "Epoch 49, Average Loss: 0.7372,MSE:0.6922646340578794\n",
      "Epoch 50, Average Loss: 0.7351,MSE:0.6886527321679518\n",
      "Epoch 51, Average Loss: 0.7322,MSE:0.7144130253929645\n",
      "Epoch 52, Average Loss: 0.7328,MSE:0.6927756863659248\n",
      "Epoch 53, Average Loss: 0.7345,MSE:0.6940997228666209\n",
      "Epoch 54, Average Loss: 0.7316,MSE:0.6919488089246676\n",
      "Epoch 55, Average Loss: 0.7331,MSE:0.6981570986520499\n",
      "Epoch 56, Average Loss: 0.7296,MSE:0.692916459370032\n",
      "Epoch 57, Average Loss: 0.7250,MSE:0.685050902088359\n",
      "Epoch 58, Average Loss: 0.7252,MSE:0.6820122882343829\n",
      "Epoch 59, Average Loss: 0.7229,MSE:0.6830698855282739\n",
      "Epoch 60, Average Loss: 0.7234,MSE:0.6944373110026121\n",
      "Epoch 61, Average Loss: 0.7220,MSE:0.677440752684325\n",
      "Epoch 62, Average Loss: 0.7194,MSE:0.6726837066862267\n",
      "Epoch 63, Average Loss: 0.7195,MSE:0.6774324995296076\n",
      "Epoch 64, Average Loss: 0.7176,MSE:0.6704744186842814\n",
      "Epoch 65, Average Loss: 0.7145,MSE:0.6735233398085461\n",
      "Epoch 66, Average Loss: 0.7151,MSE:0.6690195994578302\n",
      "Epoch 67, Average Loss: 0.7152,MSE:0.6819458361450583\n",
      "Epoch 68, Average Loss: 0.7126,MSE:0.6722665668081492\n",
      "Epoch 69, Average Loss: 0.7093,MSE:0.6630025807831437\n",
      "Epoch 70, Average Loss: 0.7072,MSE:0.6781033472146839\n",
      "Epoch 71, Average Loss: 0.7061,MSE:0.659041061373055\n",
      "Epoch 72, Average Loss: 0.7038,MSE:0.6711756537823006\n",
      "Epoch 73, Average Loss: 0.7025,MSE:0.6611585219521076\n",
      "Epoch 74, Average Loss: 0.7018,MSE:0.6505374408327043\n",
      "Epoch 75, Average Loss: 0.7007,MSE:0.6519566676102578\n",
      "Epoch 76, Average Loss: 0.7001,MSE:0.6505248373232781\n",
      "Epoch 77, Average Loss: 0.6997,MSE:0.6498837549729273\n",
      "Epoch 78, Average Loss: 0.6974,MSE:0.6453830421524123\n",
      "Epoch 79, Average Loss: 0.6972,MSE:0.6477465009594336\n",
      "Epoch 80, Average Loss: 0.6957,MSE:0.6455449236635119\n",
      "Epoch 81, Average Loss: 0.6960,MSE:0.6471457176985219\n",
      "Epoch 82, Average Loss: 0.6935,MSE:0.6431856790661812\n",
      "Epoch 83, Average Loss: 0.6947,MSE:0.6497659862536938\n",
      "Epoch 84, Average Loss: 0.6892,MSE:0.6381603938758373\n",
      "Epoch 85, Average Loss: 0.6904,MSE:0.642563635384664\n",
      "Epoch 86, Average Loss: 0.6854,MSE:0.6454109518613667\n",
      "Epoch 87, Average Loss: 0.6928,MSE:0.6505890355767682\n",
      "Epoch 88, Average Loss: 0.6940,MSE:0.6364749318135903\n",
      "Epoch 89, Average Loss: 0.6853,MSE:0.6444776561323553\n",
      "Epoch 90, Average Loss: 0.6896,MSE:0.6351600171670317\n",
      "Epoch 91, Average Loss: 0.6861,MSE:0.6381844300385564\n",
      "Epoch 92, Average Loss: 0.6864,MSE:0.6346062909873202\n",
      "Epoch 93, Average Loss: 0.6863,MSE:0.6407257423393429\n",
      "Epoch 94, Average Loss: 0.6887,MSE:0.6244098726324737\n",
      "Epoch 95, Average Loss: 0.6815,MSE:0.6253328571878374\n",
      "Epoch 96, Average Loss: 0.6779,MSE:0.6350374393071979\n",
      "Epoch 97, Average Loss: 0.6759,MSE:0.6290676797633991\n",
      "Epoch 98, Average Loss: 0.6718,MSE:0.6435748894775286\n",
      "Epoch 99, Average Loss: 0.6782,MSE:0.6241323871646076\n",
      "Epoch 100, Average Loss: 0.6812,MSE:0.6451489615473897\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "\n",
    "# 初始化 TensorBoard writer\n",
    "writer = SummaryWriter(log_dir='./log')\n",
    "\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "n_iter = 0\n",
    "Mse =[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        features, labels = data\n",
    "        user_ids = features[:, 0].long().to(device)  # 用户ID\n",
    "        movie_ids = features[:, 1].long().to(device)  # 电影ID\n",
    "        user_feats = features[:, 2:5].to(device)  # 用户特征\n",
    "        movie_feats = features[:, 5:].to(device)  # 电影特征\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_ids, movie_ids, user_feats, movie_feats)\n",
    "        prediction_clipped = predictions.clamp(min=1, max=5)\n",
    "        loss = criterion(prediction_clipped, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            n_iter += 1\n",
    "            current_loss = running_loss / 200\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {current_loss:.3f}')\n",
    "            writer.add_scalar('Loss/train', current_loss, n_iter)\n",
    "            running_loss = 0.0\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "    # 保存模型\n",
    "        PATH = './checkpoint/rating_regressor_%d.pth' % epoch\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    mse = model_eval(model,test_loader)\n",
    "    Mse.append(mse)\n",
    "    print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f},MSE:{mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0aea8bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101, Average Loss: 0.6776,MSE:0.6174963885931298\n",
      "Epoch 102, Average Loss: 0.6702,MSE:0.6156615067165345\n",
      "Epoch 103, Average Loss: 0.6700,MSE:0.6103940164234489\n",
      "Epoch 104, Average Loss: 0.6713,MSE:0.6302837017495185\n",
      "Epoch 105, Average Loss: 0.6720,MSE:0.6225634551256896\n",
      "Epoch 106, Average Loss: 0.6703,MSE:0.6074131921777501\n",
      "Epoch 107, Average Loss: 0.6707,MSE:0.6317069182826206\n",
      "Epoch 108, Average Loss: 0.6649,MSE:0.6238227596476674\n",
      "Epoch 109, Average Loss: 0.6694,MSE:0.6091211354006082\n",
      "Epoch 110, Average Loss: 0.6635,MSE:0.6087109590530395\n",
      "Epoch 111, Average Loss: 0.6668,MSE:0.6039764592236839\n",
      "Epoch 112, Average Loss: 0.6622,MSE:0.6274332544805482\n",
      "Epoch 113, Average Loss: 0.6656,MSE:0.6145241071160883\n",
      "Epoch 114, Average Loss: 0.6611,MSE:0.610173229342699\n",
      "Epoch 115, Average Loss: 0.6632,MSE:0.6032706308657303\n",
      "Epoch 116, Average Loss: 0.6596,MSE:0.6000351243756712\n",
      "Epoch 117, Average Loss: 0.6592,MSE:0.6041502215078101\n",
      "Epoch 118, Average Loss: 0.6562,MSE:0.6216999321531504\n",
      "Epoch 119, Average Loss: 0.6566,MSE:0.6052190224168822\n",
      "Epoch 120, Average Loss: 0.6504,MSE:0.5960026851297356\n",
      "Epoch 121, Average Loss: 0.6533,MSE:0.5952663552042097\n",
      "Epoch 122, Average Loss: 0.6544,MSE:0.5980084790071473\n",
      "Epoch 123, Average Loss: 0.6513,MSE:0.6180220745597035\n",
      "Epoch 124, Average Loss: 0.6538,MSE:0.6025785383414477\n",
      "Epoch 125, Average Loss: 0.6504,MSE:0.5983993303938768\n",
      "Epoch 126, Average Loss: 0.6530,MSE:0.6031807617666199\n",
      "Epoch 127, Average Loss: 0.6524,MSE:0.6108258216299116\n",
      "Epoch 128, Average Loss: 0.6493,MSE:0.6039533380454406\n",
      "Epoch 129, Average Loss: 0.6456,MSE:0.5948660466624424\n",
      "Epoch 130, Average Loss: 0.6459,MSE:0.5861229264389723\n",
      "Epoch 131, Average Loss: 0.6454,MSE:0.5916522829300724\n",
      "Epoch 132, Average Loss: 0.6419,MSE:0.6037066259589047\n",
      "Epoch 133, Average Loss: 0.6423,MSE:0.5837316403783858\n",
      "Epoch 134, Average Loss: 0.6442,MSE:0.5782389984611421\n",
      "Epoch 135, Average Loss: 0.6405,MSE:0.5783605325583369\n",
      "Epoch 136, Average Loss: 0.6412,MSE:0.5797468061428517\n",
      "Epoch 137, Average Loss: 0.6410,MSE:0.5868135903514922\n",
      "Epoch 138, Average Loss: 0.6393,MSE:0.5785576993191615\n",
      "Epoch 139, Average Loss: 0.6452,MSE:0.5951949560340494\n",
      "Epoch 140, Average Loss: 0.6434,MSE:0.5843495535196737\n",
      "Epoch 141, Average Loss: 0.6360,MSE:0.5718507108716294\n",
      "Epoch 142, Average Loss: 0.6356,MSE:0.5772832054713741\n",
      "Epoch 143, Average Loss: 0.6369,MSE:0.5782520446701906\n",
      "Epoch 144, Average Loss: 0.6354,MSE:0.5751906538168899\n",
      "Epoch 145, Average Loss: 0.6334,MSE:0.5811079462133348\n",
      "Epoch 146, Average Loss: 0.6379,MSE:0.5722856156937778\n",
      "Epoch 147, Average Loss: 0.6380,MSE:0.588563067862019\n",
      "Epoch 148, Average Loss: 0.6370,MSE:0.5849731686107814\n",
      "Epoch 149, Average Loss: 0.6397,MSE:0.6279945143867284\n",
      "Epoch 150, Average Loss: 0.6435,MSE:0.586719198118709\n",
      "Epoch 151, Average Loss: 0.6356,MSE:0.5786953499123454\n",
      "Epoch 152, Average Loss: 0.6331,MSE:0.5687355362314731\n",
      "Epoch 153, Average Loss: 0.6337,MSE:0.5645643397426233\n",
      "Epoch 154, Average Loss: 0.6367,MSE:0.5915518425961956\n",
      "Epoch 155, Average Loss: 0.6415,MSE:0.5735543502964079\n",
      "Epoch 156, Average Loss: 0.6294,MSE:0.5633701616358012\n",
      "Epoch 157, Average Loss: 0.6337,MSE:0.5690759188614786\n",
      "Epoch 158, Average Loss: 0.6315,MSE:0.5659283603798598\n",
      "Epoch 159, Average Loss: 0.6285,MSE:0.5812984951458872\n",
      "Epoch 160, Average Loss: 0.6268,MSE:0.5579294024826958\n",
      "Epoch 161, Average Loss: 0.6252,MSE:0.568616951662302\n",
      "Epoch 162, Average Loss: 0.6292,MSE:0.559106583265774\n",
      "Epoch 163, Average Loss: 0.6253,MSE:0.5696944661606104\n",
      "Epoch 164, Average Loss: 0.6271,MSE:0.5563813124023378\n",
      "Epoch 165, Average Loss: 0.6264,MSE:0.5795870070267468\n",
      "Epoch 166, Average Loss: 0.6319,MSE:0.5660732707759365\n",
      "Epoch 167, Average Loss: 0.6292,MSE:0.5698159489450976\n",
      "Epoch 168, Average Loss: 0.6299,MSE:0.567844181693904\n",
      "Epoch 169, Average Loss: 0.6221,MSE:0.5621821341237053\n",
      "Epoch 170, Average Loss: 0.6167,MSE:0.5574663968469947\n",
      "Epoch 171, Average Loss: 0.6236,MSE:0.5529272604484111\n",
      "Epoch 172, Average Loss: 0.6167,MSE:0.5628397770487703\n",
      "Epoch 173, Average Loss: 0.6204,MSE:0.5537895607138053\n",
      "Epoch 174, Average Loss: 0.6198,MSE:0.5901138648979366\n",
      "Epoch 175, Average Loss: 0.6200,MSE:0.5532942661806941\n",
      "Epoch 176, Average Loss: 0.6191,MSE:0.5733461596947164\n",
      "Epoch 177, Average Loss: 0.6244,MSE:0.568368502161093\n",
      "Epoch 178, Average Loss: 0.6242,MSE:0.5532288266364485\n",
      "Epoch 179, Average Loss: 0.6230,MSE:0.5556230890484527\n",
      "Epoch 180, Average Loss: 0.6301,MSE:0.5752837925547734\n",
      "Epoch 181, Average Loss: 0.6220,MSE:0.5477408480398357\n",
      "Epoch 182, Average Loss: 0.6167,MSE:0.5703648514583707\n",
      "Epoch 183, Average Loss: 0.6115,MSE:0.5489084577286616\n",
      "Epoch 184, Average Loss: 0.6154,MSE:0.5518532983597368\n",
      "Epoch 185, Average Loss: 0.6168,MSE:0.5514073695009575\n",
      "Epoch 186, Average Loss: 0.6157,MSE:0.5460400937264785\n",
      "Epoch 187, Average Loss: 0.6156,MSE:0.554792724462226\n",
      "Epoch 188, Average Loss: 0.6139,MSE:0.5473960370460526\n",
      "Epoch 189, Average Loss: 0.6139,MSE:0.550948370609805\n",
      "Epoch 190, Average Loss: 0.6176,MSE:0.5506255554916337\n",
      "Epoch 191, Average Loss: 0.6151,MSE:0.5582721280872822\n",
      "Epoch 192, Average Loss: 0.6184,MSE:0.5510156148249283\n",
      "Epoch 193, Average Loss: 0.6126,MSE:0.5447545402370393\n",
      "Epoch 194, Average Loss: 0.6046,MSE:0.5444291867574677\n",
      "Epoch 195, Average Loss: 0.6092,MSE:0.5416612407680601\n",
      "Epoch 196, Average Loss: 0.6047,MSE:0.5548819101341069\n",
      "Epoch 197, Average Loss: 0.6065,MSE:0.5394154373520985\n",
      "Epoch 198, Average Loss: 0.6086,MSE:0.5389338978026063\n",
      "Epoch 199, Average Loss: 0.6144,MSE:0.5470080835241824\n",
      "Epoch 200, Average Loss: 0.6213,MSE:0.5669645419381559\n",
      "Epoch 201, Average Loss: 0.6140,MSE:0.555591331239976\n",
      "Epoch 202, Average Loss: 0.6085,MSE:0.5520114435400814\n",
      "Epoch 203, Average Loss: 0.6081,MSE:0.5416594889448956\n",
      "Epoch 204, Average Loss: 0.6087,MSE:0.5386283553084359\n",
      "Epoch 205, Average Loss: 0.6071,MSE:0.5333913922611624\n",
      "Epoch 206, Average Loss: 0.6100,MSE:0.5384905188353732\n",
      "Epoch 207, Average Loss: 0.6060,MSE:0.5440626791622489\n",
      "Epoch 208, Average Loss: 0.6122,MSE:0.5644202373551205\n",
      "Epoch 209, Average Loss: 0.6206,MSE:0.5507019056914374\n",
      "Epoch 210, Average Loss: 0.6150,MSE:0.5501525051318109\n",
      "Epoch 211, Average Loss: 0.6196,MSE:0.5642883318541572\n",
      "Epoch 212, Average Loss: 0.6190,MSE:0.5681351064082235\n",
      "Epoch 213, Average Loss: 0.6192,MSE:0.549378317059204\n",
      "Epoch 214, Average Loss: 0.6147,MSE:0.5538883281867951\n",
      "Epoch 215, Average Loss: 0.6302,MSE:0.5812688096931204\n",
      "Epoch 216, Average Loss: 0.6225,MSE:0.5693888541476801\n",
      "Epoch 217, Average Loss: 0.6132,MSE:0.5691356721896679\n",
      "Epoch 218, Average Loss: 0.6160,MSE:0.5579607971526682\n",
      "Epoch 219, Average Loss: 0.6133,MSE:0.5473903672954068\n",
      "Epoch 220, Average Loss: 0.6148,MSE:0.5390155208952725\n",
      "Epoch 221, Average Loss: 0.6153,MSE:0.5624849490165711\n",
      "Epoch 222, Average Loss: 0.6260,MSE:0.5992564319614321\n",
      "Epoch 223, Average Loss: 0.6329,MSE:0.5619078098850325\n",
      "Epoch 224, Average Loss: 0.6227,MSE:0.5664146246720105\n",
      "Epoch 225, Average Loss: 0.6213,MSE:0.5582118887530639\n",
      "Epoch 226, Average Loss: 0.6251,MSE:0.5615324192220346\n",
      "Epoch 227, Average Loss: 0.6093,MSE:0.5439674406043253\n",
      "Epoch 228, Average Loss: 0.6017,MSE:0.5520331918107346\n",
      "Epoch 229, Average Loss: 0.6011,MSE:0.5400945744875818\n",
      "Epoch 230, Average Loss: 0.5945,MSE:0.5306132345084101\n",
      "Epoch 231, Average Loss: 0.5975,MSE:0.524551499649696\n",
      "Epoch 232, Average Loss: 0.5947,MSE:0.5361115122225135\n",
      "Epoch 233, Average Loss: 0.5940,MSE:0.529532749648206\n",
      "Epoch 234, Average Loss: 0.5964,MSE:0.5251915769406594\n",
      "Epoch 235, Average Loss: 0.5943,MSE:0.5294520869703964\n",
      "Epoch 236, Average Loss: 0.5958,MSE:0.519257681064494\n",
      "Epoch 237, Average Loss: 0.5905,MSE:0.5361201785293408\n",
      "Epoch 238, Average Loss: 0.5881,MSE:0.520357094413694\n",
      "Epoch 239, Average Loss: 0.5935,MSE:0.5266518018746749\n",
      "Epoch 240, Average Loss: 0.5966,MSE:0.522689355513826\n",
      "Epoch 241, Average Loss: 0.5961,MSE:0.5226582776304335\n",
      "Epoch 242, Average Loss: 0.5885,MSE:0.5169790560781956\n",
      "Epoch 243, Average Loss: 0.5930,MSE:0.5239989191612229\n",
      "Epoch 244, Average Loss: 0.5894,MSE:0.5271537941724062\n",
      "Epoch 245, Average Loss: 0.5887,MSE:0.5248860786242411\n",
      "Epoch 246, Average Loss: 0.5862,MSE:0.5225638210365549\n",
      "Epoch 247, Average Loss: 0.5855,MSE:0.5232419687495566\n",
      "Epoch 248, Average Loss: 0.5861,MSE:0.5090449629606679\n",
      "Epoch 249, Average Loss: 0.5878,MSE:0.5301601712668315\n",
      "Epoch 250, Average Loss: 0.5866,MSE:0.5280621470675804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251, Average Loss: 0.5850,MSE:0.5170409189381636\n",
      "Epoch 252, Average Loss: 0.5841,MSE:0.5109746322956867\n",
      "Epoch 253, Average Loss: 0.5876,MSE:0.5099036626946181\n",
      "Epoch 254, Average Loss: 0.5863,MSE:0.5154953235295601\n",
      "Epoch 255, Average Loss: 0.5847,MSE:0.5315893378846347\n",
      "Epoch 256, Average Loss: 0.5819,MSE:0.5510127036408521\n",
      "Epoch 257, Average Loss: 0.5803,MSE:0.510504874435626\n",
      "Epoch 258, Average Loss: 0.5788,MSE:0.5037898506363854\n",
      "Epoch 259, Average Loss: 0.5884,MSE:0.5188578464061022\n",
      "Epoch 260, Average Loss: 0.5831,MSE:0.5260272380075417\n",
      "Epoch 261, Average Loss: 0.5818,MSE:0.5035707966405898\n",
      "Epoch 262, Average Loss: 0.5857,MSE:0.5216370046235621\n",
      "Epoch 263, Average Loss: 0.5870,MSE:0.5098203676672652\n",
      "Epoch 264, Average Loss: 0.5904,MSE:0.520437976229377\n",
      "Epoch 265, Average Loss: 0.5964,MSE:0.5569791628439911\n",
      "Epoch 266, Average Loss: 0.5896,MSE:0.5202394808024168\n",
      "Epoch 267, Average Loss: 0.5902,MSE:0.5181577700207941\n",
      "Epoch 268, Average Loss: 0.5846,MSE:0.5240717034007423\n",
      "Epoch 269, Average Loss: 0.5866,MSE:0.5186660328307655\n",
      "Epoch 270, Average Loss: 0.5798,MSE:0.528301879129652\n",
      "Epoch 271, Average Loss: 0.5765,MSE:0.5027631706076674\n",
      "Epoch 272, Average Loss: 0.5798,MSE:0.5127943639222533\n",
      "Epoch 273, Average Loss: 0.5780,MSE:0.5171644934630022\n",
      "Epoch 274, Average Loss: 0.5776,MSE:0.5087647616760805\n",
      "Epoch 275, Average Loss: 0.5786,MSE:0.5088359989643096\n",
      "Epoch 276, Average Loss: 0.5790,MSE:0.5185662343529984\n",
      "Epoch 277, Average Loss: 0.5824,MSE:0.504460696682334\n",
      "Epoch 278, Average Loss: 0.5737,MSE:0.4916902847110294\n",
      "Epoch 279, Average Loss: 0.5748,MSE:0.5004355674676597\n",
      "Epoch 280, Average Loss: 0.5747,MSE:0.5155333386210724\n",
      "Epoch 281, Average Loss: 0.5773,MSE:0.5095980764286593\n",
      "Epoch 282, Average Loss: 0.5711,MSE:0.4972068425808102\n",
      "Epoch 283, Average Loss: 0.5720,MSE:0.4999545964745572\n",
      "Epoch 284, Average Loss: 0.5741,MSE:0.539444230895117\n",
      "Epoch 285, Average Loss: 0.5870,MSE:0.5280532786034048\n",
      "Epoch 286, Average Loss: 0.5878,MSE:0.5228432201486081\n",
      "Epoch 287, Average Loss: 0.5863,MSE:0.5117841757928953\n",
      "Epoch 288, Average Loss: 0.5845,MSE:0.5154519060104154\n",
      "Epoch 289, Average Loss: 0.5770,MSE:0.5023536492265761\n",
      "Epoch 290, Average Loss: 0.5901,MSE:0.5130176754049025\n",
      "Epoch 291, Average Loss: 0.5774,MSE:0.4991459341639653\n",
      "Epoch 292, Average Loss: 0.5736,MSE:0.5002584442063235\n",
      "Epoch 293, Average Loss: 0.5741,MSE:0.5009382093998603\n",
      "Epoch 294, Average Loss: 0.5741,MSE:0.5141925954477862\n",
      "Epoch 295, Average Loss: 0.5707,MSE:0.5004034164391458\n",
      "Epoch 296, Average Loss: 0.5681,MSE:0.49540729611758144\n",
      "Epoch 297, Average Loss: 0.5693,MSE:0.4997948959427886\n",
      "Epoch 298, Average Loss: 0.5737,MSE:0.5089644900007639\n",
      "Epoch 299, Average Loss: 0.5670,MSE:0.4986755332339555\n",
      "Epoch 300, Average Loss: 0.5662,MSE:0.49205859875539315\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100,300):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        features, labels = data\n",
    "        user_ids = features[:, 0].long().to(device)  # 用户ID\n",
    "        movie_ids = features[:, 1].long().to(device)  # 电影ID\n",
    "        user_feats = features[:, 2:5].to(device)  # 用户特征\n",
    "        movie_feats = features[:, 5:].to(device)  # 电影特征\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_ids, movie_ids, user_feats, movie_feats)\n",
    "        prediction_clipped = predictions.clamp(min=1, max=5)\n",
    "        loss = criterion(prediction_clipped, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            n_iter += 1\n",
    "            current_loss = running_loss / 200\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {current_loss:.3f}')\n",
    "            writer.add_scalar('Loss/train', current_loss, n_iter)\n",
    "            running_loss = 0.0\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "    # 保存模型\n",
    "        PATH = './checkpoint/rating_regressor_%d.pth' % epoch\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    mse = model_eval(model,test_loader)\n",
    "    Mse.append(mse)\n",
    "    print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f},MSE:{mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "626052fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299 15000\n"
     ]
    }
   ],
   "source": [
    "print(epoch,n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5136885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 TensorBoard writer\n",
    "writer = SummaryWriter(log_dir='./log')\n",
    "\n",
    "# epoch = 300 其实是301轮\n",
    "PATH = './checkpoint/rating_regressor_300.pth'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "n_iter = 15000\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "Mse = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6f7c648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301, Average Loss: 0.5721,MSE:0.5102098921283148\n",
      "Epoch 302, Average Loss: 0.5720,MSE:0.49653612046614287\n",
      "Epoch 303, Average Loss: 0.5689,MSE:0.49656740480400624\n",
      "Epoch 304, Average Loss: 0.5662,MSE:0.5004581382468343\n",
      "Epoch 305, Average Loss: 0.5654,MSE:0.4891149421745911\n",
      "Epoch 306, Average Loss: 0.5658,MSE:0.4862265779586509\n",
      "Epoch 307, Average Loss: 0.5692,MSE:0.49655870473962277\n",
      "Epoch 308, Average Loss: 0.5668,MSE:0.4795576021321118\n",
      "Epoch 309, Average Loss: 0.5652,MSE:0.49237255536196756\n",
      "Epoch 310, Average Loss: 0.5654,MSE:0.4984518022755161\n",
      "Epoch 311, Average Loss: 0.5640,MSE:0.4887421263065189\n",
      "Epoch 312, Average Loss: 0.5640,MSE:0.4974765215570107\n",
      "Epoch 313, Average Loss: 0.5652,MSE:0.4985065401038155\n",
      "Epoch 314, Average Loss: 0.5613,MSE:0.48516979700028895\n",
      "Epoch 315, Average Loss: 0.5627,MSE:0.48887550071608277\n",
      "Epoch 316, Average Loss: 0.5603,MSE:0.49014481675196436\n",
      "Epoch 317, Average Loss: 0.5599,MSE:0.49262747214678676\n",
      "Epoch 318, Average Loss: 0.5608,MSE:0.4798320465106517\n",
      "Epoch 319, Average Loss: 0.5614,MSE:0.4928919578349218\n",
      "Epoch 320, Average Loss: 0.5618,MSE:0.48228210717309267\n",
      "Epoch 321, Average Loss: 0.5584,MSE:0.4911133936395869\n",
      "Epoch 322, Average Loss: 0.5680,MSE:0.48401398203596474\n",
      "Epoch 323, Average Loss: 0.5599,MSE:0.4972484403844923\n",
      "Epoch 324, Average Loss: 0.5659,MSE:0.49434377410849556\n",
      "Epoch 325, Average Loss: 0.5667,MSE:0.501119775969442\n",
      "Epoch 326, Average Loss: 0.5692,MSE:0.4889840929731727\n",
      "Epoch 327, Average Loss: 0.5694,MSE:0.4950335761979222\n",
      "Epoch 328, Average Loss: 0.5637,MSE:0.4875650693226606\n",
      "Epoch 329, Average Loss: 0.5561,MSE:0.4903372538490221\n",
      "Epoch 330, Average Loss: 0.5560,MSE:0.5013139444836415\n",
      "Epoch 331, Average Loss: 0.5600,MSE:0.4885882675414905\n",
      "Epoch 332, Average Loss: 0.5644,MSE:0.49069856768641623\n",
      "Epoch 333, Average Loss: 0.5590,MSE:0.47796162789752705\n",
      "Epoch 334, Average Loss: 0.5602,MSE:0.49021896562948825\n",
      "Epoch 335, Average Loss: 0.5584,MSE:0.4819489943429828\n",
      "Epoch 336, Average Loss: 0.5518,MSE:0.47535952568165957\n",
      "Epoch 337, Average Loss: 0.5547,MSE:0.5091105150767602\n",
      "Epoch 338, Average Loss: 0.5514,MSE:0.4759531190083362\n",
      "Epoch 339, Average Loss: 0.5481,MSE:0.48831004847036674\n",
      "Epoch 340, Average Loss: 0.5547,MSE:0.4731828862868249\n",
      "Epoch 341, Average Loss: 0.5571,MSE:0.47636556766182186\n",
      "Epoch 342, Average Loss: 0.5586,MSE:0.47343151992186905\n",
      "Epoch 343, Average Loss: 0.5545,MSE:0.4929000227713492\n",
      "Epoch 344, Average Loss: 0.5725,MSE:0.49352310850434006\n",
      "Epoch 345, Average Loss: 0.5637,MSE:0.47864347188351675\n",
      "Epoch 346, Average Loss: 0.5524,MSE:0.4831942095594481\n",
      "Epoch 347, Average Loss: 0.5486,MSE:0.4654101750885136\n",
      "Epoch 348, Average Loss: 0.5591,MSE:0.48897680685487577\n",
      "Epoch 349, Average Loss: 0.5617,MSE:0.48634020043872295\n",
      "Epoch 350, Average Loss: 0.5545,MSE:0.48463215756509453\n",
      "Epoch 351, Average Loss: 0.5548,MSE:0.4729940560899675\n",
      "Epoch 352, Average Loss: 0.5636,MSE:0.48991612410880625\n",
      "Epoch 353, Average Loss: 0.5613,MSE:0.4926590415468439\n",
      "Epoch 354, Average Loss: 0.5608,MSE:0.4920862344166264\n",
      "Epoch 355, Average Loss: 0.5656,MSE:0.48914446871522815\n",
      "Epoch 356, Average Loss: 0.5684,MSE:0.49278901528194546\n",
      "Epoch 357, Average Loss: 0.5601,MSE:0.4807597097273916\n",
      "Epoch 358, Average Loss: 0.5536,MSE:0.4819440452046692\n",
      "Epoch 359, Average Loss: 0.5519,MSE:0.48203914404585957\n",
      "Epoch 360, Average Loss: 0.5490,MSE:0.47110189002994446\n",
      "Epoch 361, Average Loss: 0.5511,MSE:0.4736565501942299\n",
      "Epoch 362, Average Loss: 0.5559,MSE:0.4873294477669522\n",
      "Epoch 363, Average Loss: 0.5542,MSE:0.4844883824219927\n",
      "Epoch 364, Average Loss: 0.5488,MSE:0.4800922239460051\n",
      "Epoch 365, Average Loss: 0.5557,MSE:0.5164149197201943\n",
      "Epoch 366, Average Loss: 0.5561,MSE:0.4808156160896644\n",
      "Epoch 367, Average Loss: 0.5519,MSE:0.4809013749951497\n",
      "Epoch 368, Average Loss: 0.5478,MSE:0.4939891312136082\n",
      "Epoch 369, Average Loss: 0.5463,MSE:0.4606362864722032\n",
      "Epoch 370, Average Loss: 0.5445,MSE:0.47106303194351495\n",
      "Epoch 371, Average Loss: 0.5487,MSE:0.4781620289643295\n",
      "Epoch 372, Average Loss: 0.5476,MSE:0.46372272936888037\n",
      "Epoch 373, Average Loss: 0.5455,MSE:0.46476831347290426\n",
      "Epoch 374, Average Loss: 0.5437,MSE:0.46336925274338575\n",
      "Epoch 375, Average Loss: 0.5492,MSE:0.4743175042828545\n",
      "Epoch 376, Average Loss: 0.5570,MSE:0.48729500366151335\n",
      "Epoch 377, Average Loss: 0.5549,MSE:0.4763371426844038\n",
      "Epoch 378, Average Loss: 0.5463,MSE:0.46832637689970436\n",
      "Epoch 379, Average Loss: 0.5437,MSE:0.46009427049215884\n",
      "Epoch 380, Average Loss: 0.5448,MSE:0.46643690260313453\n",
      "Epoch 381, Average Loss: 0.5459,MSE:0.4804631472698413\n",
      "Epoch 382, Average Loss: 0.5413,MSE:0.4551520706124604\n",
      "Epoch 383, Average Loss: 0.5398,MSE:0.46007408338971434\n",
      "Epoch 384, Average Loss: 0.5375,MSE:0.4724744664825499\n",
      "Epoch 385, Average Loss: 0.5377,MSE:0.46013604190144686\n",
      "Epoch 386, Average Loss: 0.5435,MSE:0.4610751201157458\n",
      "Epoch 387, Average Loss: 0.5409,MSE:0.4670691492238082\n",
      "Epoch 388, Average Loss: 0.5403,MSE:0.46579968277439476\n",
      "Epoch 389, Average Loss: 0.5496,MSE:0.4634418423594907\n",
      "Epoch 390, Average Loss: 0.5460,MSE:0.46515415647113695\n",
      "Epoch 391, Average Loss: 0.5435,MSE:0.46570468497183176\n",
      "Epoch 392, Average Loss: 0.5402,MSE:0.4643297178570181\n",
      "Epoch 393, Average Loss: 0.5473,MSE:0.4611919343751855\n",
      "Epoch 394, Average Loss: 0.5463,MSE:0.481044518380519\n",
      "Epoch 395, Average Loss: 0.5435,MSE:0.47096469646403566\n",
      "Epoch 396, Average Loss: 0.5462,MSE:0.4879874441754073\n",
      "Epoch 397, Average Loss: 0.5427,MSE:0.4514519144388847\n",
      "Epoch 398, Average Loss: 0.5378,MSE:0.47803347494890913\n",
      "Epoch 399, Average Loss: 0.5409,MSE:0.45725426848940554\n",
      "Epoch 400, Average Loss: 0.5377,MSE:0.452216859938018\n",
      "Epoch 401, Average Loss: 0.5360,MSE:0.4592940177013166\n",
      "Epoch 402, Average Loss: 0.5436,MSE:0.45945447145290674\n",
      "Epoch 403, Average Loss: 0.5374,MSE:0.4656990908351727\n",
      "Epoch 404, Average Loss: 0.5342,MSE:0.44050684948321434\n",
      "Epoch 405, Average Loss: 0.5340,MSE:0.4458944603456184\n",
      "Epoch 406, Average Loss: 0.5307,MSE:0.44567898144088686\n",
      "Epoch 407, Average Loss: 0.5295,MSE:0.45157254743594677\n",
      "Epoch 408, Average Loss: 0.5334,MSE:0.4571606663449667\n",
      "Epoch 409, Average Loss: 0.5345,MSE:0.44060376046989114\n",
      "Epoch 410, Average Loss: 0.5322,MSE:0.44741757549773903\n",
      "Epoch 411, Average Loss: 0.5289,MSE:0.4429789249204099\n",
      "Epoch 412, Average Loss: 0.5272,MSE:0.44486326538063586\n",
      "Epoch 413, Average Loss: 0.5264,MSE:0.45581987846717237\n",
      "Epoch 414, Average Loss: 0.5260,MSE:0.44184559692442416\n",
      "Epoch 415, Average Loss: 0.5284,MSE:0.44165623582424596\n",
      "Epoch 416, Average Loss: 0.5296,MSE:0.4524441811447963\n",
      "Epoch 417, Average Loss: 0.5296,MSE:0.4589484673860483\n",
      "Epoch 418, Average Loss: 0.5327,MSE:0.4585684772500768\n",
      "Epoch 419, Average Loss: 0.5431,MSE:0.45453268574364486\n",
      "Epoch 420, Average Loss: 0.5368,MSE:0.4449606306754984\n",
      "Epoch 421, Average Loss: 0.5291,MSE:0.46046524979127573\n",
      "Epoch 422, Average Loss: 0.5320,MSE:0.4578156852557324\n",
      "Epoch 423, Average Loss: 0.5311,MSE:0.45911426868001\n",
      "Epoch 424, Average Loss: 0.5293,MSE:0.4475207025418058\n",
      "Epoch 425, Average Loss: 0.5264,MSE:0.44651824635220694\n",
      "Epoch 426, Average Loss: 0.5174,MSE:0.4450202755212784\n",
      "Epoch 427, Average Loss: 0.5270,MSE:0.4393960244929418\n",
      "Epoch 428, Average Loss: 0.5261,MSE:0.4500377002270892\n",
      "Epoch 429, Average Loss: 0.5248,MSE:0.42876782838469374\n",
      "Epoch 430, Average Loss: 0.5238,MSE:0.43736709728976714\n",
      "Epoch 431, Average Loss: 0.5239,MSE:0.4395083867041394\n",
      "Epoch 432, Average Loss: 0.5232,MSE:0.4641825722223148\n",
      "Epoch 433, Average Loss: 0.5243,MSE:0.43606807809714226\n",
      "Epoch 434, Average Loss: 0.5238,MSE:0.44578144917851314\n",
      "Epoch 435, Average Loss: 0.5223,MSE:0.438782578737475\n",
      "Epoch 436, Average Loss: 0.5239,MSE:0.4329705345850438\n",
      "Epoch 437, Average Loss: 0.5214,MSE:0.44404857903486117\n",
      "Epoch 438, Average Loss: 0.5311,MSE:0.4344954721025191\n",
      "Epoch 439, Average Loss: 0.5270,MSE:0.4521071725668386\n",
      "Epoch 440, Average Loss: 0.5244,MSE:0.4504610849220306\n",
      "Epoch 441, Average Loss: 0.5235,MSE:0.45004485492971724\n",
      "Epoch 442, Average Loss: 0.5174,MSE:0.43393610060904175\n",
      "Epoch 443, Average Loss: 0.5190,MSE:0.4488265726240352\n",
      "Epoch 444, Average Loss: 0.5176,MSE:0.4489269030525349\n",
      "Epoch 445, Average Loss: 0.5181,MSE:0.4446300477116369\n",
      "Epoch 446, Average Loss: 0.5212,MSE:0.42542244361853226\n",
      "Epoch 447, Average Loss: 0.5201,MSE:0.44157530633881686\n",
      "Epoch 448, Average Loss: 0.5256,MSE:0.43654477969473227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449, Average Loss: 0.5252,MSE:0.44574770868839697\n",
      "Epoch 450, Average Loss: 0.5226,MSE:0.4374747435931116\n",
      "Epoch 451, Average Loss: 0.5180,MSE:0.43396288481298834\n",
      "Epoch 452, Average Loss: 0.5181,MSE:0.4492287138755433\n",
      "Epoch 453, Average Loss: 0.5335,MSE:0.4472656191494316\n",
      "Epoch 454, Average Loss: 0.5295,MSE:0.43613609321331603\n",
      "Epoch 455, Average Loss: 0.5250,MSE:0.42817548456704246\n",
      "Epoch 456, Average Loss: 0.5210,MSE:0.4401831533331424\n",
      "Epoch 457, Average Loss: 0.5207,MSE:0.43065154531318695\n",
      "Epoch 458, Average Loss: 0.5160,MSE:0.4375519964477047\n",
      "Epoch 459, Average Loss: 0.5132,MSE:0.42444718906600026\n",
      "Epoch 460, Average Loss: 0.5157,MSE:0.4481226414234843\n",
      "Epoch 461, Average Loss: 0.5184,MSE:0.43680107375988736\n",
      "Epoch 462, Average Loss: 0.5153,MSE:0.42778881237953903\n",
      "Epoch 463, Average Loss: 0.5186,MSE:0.4410879035125487\n",
      "Epoch 464, Average Loss: 0.5158,MSE:0.42644169247280805\n",
      "Epoch 465, Average Loss: 0.5131,MSE:0.43101925196647645\n",
      "Epoch 466, Average Loss: 0.5155,MSE:0.42716942497245036\n",
      "Epoch 467, Average Loss: 0.5201,MSE:0.4288591593760997\n",
      "Epoch 468, Average Loss: 0.5197,MSE:0.4363629083137959\n",
      "Epoch 469, Average Loss: 0.5163,MSE:0.47223849565091075\n",
      "Epoch 470, Average Loss: 0.5210,MSE:0.43144796529803425\n",
      "Epoch 471, Average Loss: 0.5190,MSE:0.44567748065143825\n",
      "Epoch 472, Average Loss: 0.5176,MSE:0.4425835639219731\n",
      "Epoch 473, Average Loss: 0.5139,MSE:0.4264573717907071\n",
      "Epoch 474, Average Loss: 0.5121,MSE:0.4290088649898767\n",
      "Epoch 475, Average Loss: 0.5129,MSE:0.42746395040340723\n",
      "Epoch 476, Average Loss: 0.5107,MSE:0.4160472005466465\n",
      "Epoch 477, Average Loss: 0.5115,MSE:0.41862225283943116\n",
      "Epoch 478, Average Loss: 0.5080,MSE:0.43015269512254745\n",
      "Epoch 479, Average Loss: 0.5102,MSE:0.4272136861402541\n",
      "Epoch 480, Average Loss: 0.5134,MSE:0.44257437834478913\n",
      "Epoch 481, Average Loss: 0.5128,MSE:0.446504816923663\n",
      "Epoch 482, Average Loss: 0.5134,MSE:0.43246134521448987\n",
      "Epoch 483, Average Loss: 0.5110,MSE:0.4363990468310192\n",
      "Epoch 484, Average Loss: 0.5116,MSE:0.43632687333086506\n",
      "Epoch 485, Average Loss: 0.5163,MSE:0.41748878890573976\n",
      "Epoch 486, Average Loss: 0.5146,MSE:0.4432632704026997\n",
      "Epoch 487, Average Loss: 0.5153,MSE:0.4225243207072839\n",
      "Epoch 488, Average Loss: 0.5162,MSE:0.44488995013614185\n",
      "Epoch 489, Average Loss: 0.5152,MSE:0.4195845416298136\n",
      "Epoch 490, Average Loss: 0.5145,MSE:0.42331433657919987\n",
      "Epoch 491, Average Loss: 0.5148,MSE:0.41893834419436754\n",
      "Epoch 492, Average Loss: 0.5087,MSE:0.41817749585616404\n",
      "Epoch 493, Average Loss: 0.5141,MSE:0.42704586002230643\n",
      "Epoch 494, Average Loss: 0.5173,MSE:0.43267833387274296\n",
      "Epoch 495, Average Loss: 0.5156,MSE:0.4252685139603913\n",
      "Epoch 496, Average Loss: 0.5101,MSE:0.4236003187183291\n",
      "Epoch 497, Average Loss: 0.5154,MSE:0.4265964043016546\n",
      "Epoch 498, Average Loss: 0.5164,MSE:0.4200166645359248\n",
      "Epoch 499, Average Loss: 0.5097,MSE:0.4222272207411006\n",
      "Epoch 500, Average Loss: 0.5131,MSE:0.417286721601896\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(300,500):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_loss = 0\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "        features, labels = data\n",
    "        user_ids = features[:, 0].long().to(device)  # 用户ID\n",
    "        movie_ids = features[:, 1].long().to(device)  # 电影ID\n",
    "        user_feats = features[:, 2:5].to(device)  # 用户特征\n",
    "        movie_feats = features[:, 5:].to(device)  # 电影特征\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_ids, movie_ids, user_feats, movie_feats)\n",
    "        prediction_clipped = predictions.clamp(min=1, max=5)\n",
    "        loss = criterion(prediction_clipped, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        if i % 200 == 199:\n",
    "            n_iter += 1\n",
    "            current_loss = running_loss / 200\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {current_loss:.3f}')\n",
    "            writer.add_scalar('Loss/train', current_loss, n_iter)\n",
    "            running_loss = 0.0\n",
    "        \n",
    "    if epoch % 10 == 0 or epoch == 499:\n",
    "    # 保存模型\n",
    "        PATH = './checkpoint/rating_regressor_%d.pth' % epoch\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    mse = model_eval(model,test_loader)\n",
    "    Mse.append(mse)\n",
    "    print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f},MSE:{mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6f03567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "PATH = './rating_regressor_100.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66655424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f5750ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1,MSE:1.1314000712901353\n",
      "Epoch2,MSE:0.9893959114834666\n",
      "Epoch3,MSE:0.9135288128580898\n",
      "Epoch4,MSE:0.9480244465880096\n",
      "Epoch5,MSE:0.9040041882034391\n",
      "Epoch6,MSE:0.9248678304813802\n",
      "Epoch7,MSE:0.8657799772314727\n",
      "Epoch8,MSE:0.8704155466578901\n",
      "Epoch9,MSE:0.8364718932341785\n",
      "Epoch10,MSE:0.8426222413949669\n",
      "Epoch11,MSE:0.8694272248327732\n",
      "Epoch12,MSE:0.8402617111448198\n",
      "Epoch13,MSE:0.8119284650109708\n",
      "Epoch14,MSE:0.8600026292067021\n",
      "Epoch15,MSE:0.8142544409230351\n",
      "Epoch16,MSE:0.8075948779158294\n",
      "Epoch17,MSE:0.8250312206327916\n",
      "Epoch18,MSE:0.8033192804407329\n",
      "Epoch19,MSE:0.8301366760080681\n",
      "Epoch20,MSE:0.8119040590371936\n",
      "Epoch21,MSE:0.7827515818532557\n",
      "Epoch22,MSE:0.789468156767264\n",
      "Epoch23,MSE:0.7786395530339331\n",
      "Epoch24,MSE:0.7753198533548042\n",
      "Epoch25,MSE:0.7863074863614514\n",
      "Epoch26,MSE:0.7637563189782203\n",
      "Epoch27,MSE:0.7673834804572165\n",
      "Epoch28,MSE:0.7678374211218209\n",
      "Epoch29,MSE:0.7696959763046354\n",
      "Epoch30,MSE:0.7710029992304742\n",
      "Epoch31,MSE:0.7579973260758445\n",
      "Epoch32,MSE:0.7489544375460595\n",
      "Epoch33,MSE:0.7374630538225174\n",
      "Epoch34,MSE:0.7374102786857635\n",
      "Epoch35,MSE:0.7475707625102251\n",
      "Epoch36,MSE:0.7485739359633997\n",
      "Epoch37,MSE:0.727391458395496\n",
      "Epoch38,MSE:0.7230869594767689\n",
      "Epoch39,MSE:0.7210107688471675\n",
      "Epoch40,MSE:0.7250137717336417\n",
      "Epoch41,MSE:0.7119329386491329\n",
      "Epoch42,MSE:0.7109848469603807\n",
      "Epoch43,MSE:0.7255169413072988\n",
      "Epoch44,MSE:0.7047073085254059\n",
      "Epoch45,MSE:0.6981879500541835\n",
      "Epoch46,MSE:0.6977664839394391\n",
      "Epoch47,MSE:0.6963163664158434\n",
      "Epoch48,MSE:0.7150468526205048\n",
      "Epoch49,MSE:0.6922646340578794\n",
      "Epoch50,MSE:0.6886527321679518\n",
      "Epoch51,MSE:0.7144130253929645\n",
      "Epoch52,MSE:0.6927756863659248\n",
      "Epoch53,MSE:0.6940997228666209\n",
      "Epoch54,MSE:0.6919488089246676\n",
      "Epoch55,MSE:0.6981570986520499\n",
      "Epoch56,MSE:0.692916459370032\n",
      "Epoch57,MSE:0.685050902088359\n",
      "Epoch58,MSE:0.6820122882343829\n",
      "Epoch59,MSE:0.6830698855282739\n",
      "Epoch60,MSE:0.6944373110026121\n",
      "Epoch61,MSE:0.677440752684325\n",
      "Epoch62,MSE:0.6726837066862267\n",
      "Epoch63,MSE:0.6774324995296076\n",
      "Epoch64,MSE:0.6704744186842814\n",
      "Epoch65,MSE:0.6735233398085461\n",
      "Epoch66,MSE:0.6690195994578302\n",
      "Epoch67,MSE:0.6819458361450583\n",
      "Epoch68,MSE:0.6722665668081492\n",
      "Epoch69,MSE:0.6630025807831437\n",
      "Epoch70,MSE:0.6781033472146839\n",
      "Epoch71,MSE:0.659041061373055\n",
      "Epoch72,MSE:0.6711756537823006\n",
      "Epoch73,MSE:0.6611585219521076\n",
      "Epoch74,MSE:0.6505374408327043\n",
      "Epoch75,MSE:0.6519566676102578\n",
      "Epoch76,MSE:0.6505248373232781\n",
      "Epoch77,MSE:0.6498837549729273\n",
      "Epoch78,MSE:0.6453830421524123\n",
      "Epoch79,MSE:0.6477465009594336\n",
      "Epoch80,MSE:0.6455449236635119\n",
      "Epoch81,MSE:0.6471457176985219\n",
      "Epoch82,MSE:0.6431856790661812\n",
      "Epoch83,MSE:0.6497659862536938\n",
      "Epoch84,MSE:0.6381603938758373\n",
      "Epoch85,MSE:0.642563635384664\n",
      "Epoch86,MSE:0.6454109518613667\n",
      "Epoch87,MSE:0.6505890355767682\n",
      "Epoch88,MSE:0.6364749318135903\n",
      "Epoch89,MSE:0.6444776561323553\n",
      "Epoch90,MSE:0.6351600171670317\n",
      "Epoch91,MSE:0.6381844300385564\n",
      "Epoch92,MSE:0.6346062909873202\n",
      "Epoch93,MSE:0.6407257423393429\n",
      "Epoch94,MSE:0.6244098726324737\n",
      "Epoch95,MSE:0.6253328571878374\n",
      "Epoch96,MSE:0.6350374393071979\n",
      "Epoch97,MSE:0.6290676797633991\n",
      "Epoch98,MSE:0.6435748894775286\n",
      "Epoch99,MSE:0.6241323871646076\n",
      "Epoch100,MSE:0.6451489615473897\n"
     ]
    }
   ],
   "source": [
    "for i,mse in enumerate(Mse):\n",
    "    print(f'Epoch{i+1},MSE:{mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69dfef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "py10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
